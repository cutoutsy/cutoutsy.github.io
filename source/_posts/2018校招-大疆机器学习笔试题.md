---
layout: post
title: 2018校招-大疆机器学习笔试题
categories: 算法
date: 2018-07-08 20:54:44
tags:
    - 2018校招
    - 大疆
    - 笔试
---
### 写在前面
本篇博客写的是关于大疆机器学习岗位的笔试题B卷（分两次考试：A卷和B卷），对其他岗位不具有参考性。今年的大疆笔试题题量大（单选，多选，填空，问答，编程），时间却很短（1个小时），可以说是时间短，题目多。好多人都没有做完，包括我。不说了，趁着刚做完，把题目做一个记录，题目来自于一些同学的拍照和自己的记忆。

### 题目
#### 单选题

<!-- more -->
1\. 关于Logistic回归和SVM，以下说法错误的是？
> * Logistic回归可用于预测事件发生概率的大小
> * Logistic回归的目标函数是最小化后验概率
> * SVM的目标的结构风险最小化
> * SVM可以有效避免模型过拟合

2\. 假设三个稠密矩阵（Dense Matrix）A, B, C的尺寸分别为m\*n, n\*q和p\*q，且$m<n<p<q$，一下计算顺序会加速的是？
> * (AB)C
> * AC(B)
> * A(BC)
> * 所有效率都相同

答案：A

3\. 以下有关特征数据归一化的说法错误的是：
> * 特征数据归一化加速梯度下降优化的速度
> * 特征数据归一化有可能提高模型的精度
> * 线性归一化适用于特征数值分化比较大的情况
> * 概率模型不需要做归一化处理

4\. 假定你在神经网络中的隐藏层中使用激活函数X，在特定神经元给定任意输入，你会得到输出[-0.0001]，X可能是一下哪一个？
> * ReLU
> * tanh
> * sigmoid
> * 其他都不是

5\. 下列哪些项所描述的相关技术是对的？
> * AdaGrad和L-BFGS使用的都是一阶差分
> * AdaGrad和L-BFGS使用的都是二阶差分
> * Adagrad使用的是一阶差分，L-BFGS使用的是二阶差分
> * Adagrad使用的是二阶差分，L-BFGS使用的是一阶差分

#### 多选题
1\. 关于主成分分析PCA说法正确的是：
> * 我们必须在使用PCA前规范化数据
> * 我们应该选择使得模型有最大variance的主成分
> * 我们应该选择使得模型有最小variance的主成分
> * 我们可以使用PCA在低纬度上做数据可视化

2\. 以下描述错误的是？
> * SVM是这样一个分类器，他寻找具有最小边缘的超平面，因此它也经常被称为最小边缘分类器（minimal margin classifier）
> * 在聚类分析中，簇内的相似性越大，簇间的差别越大，聚类的效果越好
> * 在决策树中，随着树中节点变得太大，即使模型的训练误差还在继续减低，但是检验误差开始增大，这是出现了模型拟合不足的问题
> * 聚类分析可以看做是一种非监督的分类

3\. 假设目标遍历的类别非常不平衡，即主要类别占据了训练数据的99%，现在你的模型在训练集上表现为99%的准确度，那么下面说法正确的是：
> * 准确度并不适合衡量不平衡类别问题
> * 准确度适合衡量不平衡类别问题
> * 精确度和召回率适合于衡量不平衡类别问题
> * 精确度和召回率不适合衡量不平衡类别问题

4\. 神经网络训练过程中的哪些现象表明可能出现了梯度爆炸？
> * 模型梯度快速变大
> * 模型权重变为NaN值
> * 每个节点和层的误差梯度值持续超多1.0
> * 损失函数持续减小

应该还有个第五题，不过没有资料了。

#### 填空题
1\. 具体题目记不太清楚了，是关于输如一个200x200的图像，经过几次卷积和池化后，求维度大小。
2\. 在训练集标签为[0,0,0,1,1,1,1,1], 求信息熵的大小。

### 简答题
1\. BP算法推导
2\. 写出Leaky-ReLu的数学公式，相对于sigmoid函数的优点
3\. Adagrad的优缺点
4\. 在图像处理中，Data augmentation有哪些方式
5\. 为什么要进行数据归一化，有哪些方式

#### 编程题
1\. 给你一个数列a[0], n[1],...,a[n-1]，n大于4，必定存在i, j, p, q, 使得$i<j<p<q$，且$n[j] - n[i] + n[q]-n[p]$值最大，求出这个最大值，并说明时间复杂度。

2\. 给你一个数组，求一个k值，使得前k个数的方差+后面n-k个数的方差最小，并说明时间复杂度。